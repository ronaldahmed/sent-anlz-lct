%
% File naacl2019.tex
%
%% Based on the style files for ACL 2018 and NAACL 2018, which were
%% Based on the style files for ACL-2015, with some improvements
%%  taken from the NAACL-2016 style
%% Based on the style files for ACL-2014, which were, in turn,
%% based on ACL-2013, ACL-2012, ACL-2011, ACL-2010, ACL-IJCNLP-2009,
%% EACL-2009, IJCNLP-2008...
%% Based on the style files for EACL 2006 by 
%%e.agirre@ehu.es or Sergi.Balari@uab.es
%% and that of ACL 08 by Joakim Nivre and Noah Smith

\documentclass[11pt,a4paper]{article}
\usepackage[hyperref]{naaclhlt2019}
\usepackage{times}
\usepackage{latexsym}
\usepackage{amsfonts}

\usepackage{url}

%\aclfinalcopy % Uncomment this line for the final submission
%\def\aclpaperid{***} %  Enter the acl Paper ID here

%\setlength\titlebox{5cm}
% You can expand the titlebox if you need extra space
% to show all the authors. Please do not make the titlebox
% smaller than 5cm (the original size); we will check this
% in the camera-ready version and ask you to change it back.

\newcommand\BibTeX{B{\sc ib}\TeX}

\title{Cross-domain Soft Patterns for Sentiment Analysis}

\author{Ronald Cardenas Acosta\\
  University of Malta \\
  {\tt ronald.cardenas.18@um.edu.mt} \\}

\date{}

\begin{document}
\maketitle
\begin{abstract}
  This report describes experiments 
\end{abstract}


\section{Introduction}

%what is domain adaptation

The objective of domain adaptation techniques is to adapt a hypothesis trained on a source data distribution so that it can perform well on a related target distribution.
These techniques have been applied to a variety of NLP tasks such as sentiment analysis \cite{blitzer2007biographies,mcauley2013hidden,mcauley2015image,ruder2018strong}, style transfer in text generation \cite{fu2018style,NIPS2018_7959,peng-etal-2018-towards}, textual and visual question answering \cite{chao2018cross,zhao2018finding}, and machine translation \cite{etchegoyhen2018evaluating,britz2017effective}, to name a few.

In the case of sentiment analysis of online user reviews, previous work has sought effective ways of transfer learning between product categories \cite{blitzer2007biographies,ruder2018strong}. However, the task has been proven to be challenging since sentiment is expressed differently in different domains.
For instance, \citet{blitzer2007biographies} identifies three types of feature behaviour across domains: (a) features that are highly predictive in the source domain but not in the target domain, (b) features that are highly predictive in the target domain but not in the source domain, and (c) features that positively predictive in the source domain but negatively predictive in the target domain (or viceversa).

In this report, we focus on unsupervised domain adaptation for the task of sentiment analysis, transfering from a single source domain into a single target domain.
We build upon the recently proposed {\sc SoPa} \cite{schwartz2018sopa}, a neural architecture that mimic the behaviour of a Weighted Finite State Machine.
{\sc SoPa} is able to learn soft lexical patterns, i.e.\ word patterns that might include a (possibly empty) wild card.
We investigate the performance of {\sc SoPa} under a self-training setup following calibration procedures proposed by \citet{ruder2018strong}.
Experiments on Amazon online reviews of two product categires show promising results.

% what is sent analizis
% why is domain adp important for sent analisis
% what we are introducing
%	 build upon ---
% on what data, which domains, method, 
% contributions?


\section{Related Work}

Early work on domain adaptation for sentiment analysis, namely non-neural approaches, reports that transfering from a source domain closer to the target domain yields better performance than combining several significantly varied domains \cite{blitzer2007biographies,aue2005customizing}.
One identified reason is the vocabulary mismatch between domains, leading to scenarios where features drawn from one domain are not present in the other or contradict each other, as reported by \citet{blitzer2007biographies}.
In the advent of neural networks, this problem is partially addressed with continuous representation of words. A more direct approach is taken by \citet{barnes2018projecting} who projects embeddings from both source and target domains into a common space in an adversarial setup.
Furthermore, most neural architectures proposed so far rely on pretrained word embeddings that could be considered domain-independent given the datasets these embededdings trained on \cite{pennington2014glove,Peters:2018}. These huge benmark datasets are meant to be as varied as possible in terms of domains, e.g. Wikipedia, CommonCrawl.

However, highly specific domains will present word types that are likely not represented in these pretrained representations. In this case, a model will rely on the embedding module's robutness to represent OOV types. In this scenario, \cite{schwartz2018sopa} proposes {\sc SoPa}, a model that mimics the behaviour of a Weighted Finite State Machine. The model itself can be regarded as a restricted case of a one-layer CNN that consumes the input one token at a time, like an RNN. The architecture shifts the representation robustness from the token level to the phrase level by modelling a soft version of traditional lexical patterns. The model learns to represent fixed-length patterns of words with possibly empty components. For example, a pattern can match  the sequence {\it A B C} as well as {\it A * C}.

The performance of {\sc SoPa} is tested by \citet{schwartz2018sopa} for the task of sentiment analysis in single domain scenarios. In this report, we investigate the performance of  {\sc SoPa} under a transfer learning scenario from one source domain (Movies \& TV) to one target domain (Games).

% how prev work struggled because of vocabulary mismatch
% sopa does well on sent analisis on one-domain
% sopa's flexibility to match patterns with * or missing elements
% --> chance to explicitly model vocab mismatch
% sopa repr is orthogonal to sota models, can be used as an extra repr layer on top of word embeddings

\section{Soft Patterns}

A soft pattern, as introduced by \citet{davidov2010enhanced}, is a pattern that supports partial matching on a given span of text by skipping some words of the pattern.
Let WFSA-$\epsilon$ be a WFSA that support $\epsilon$ transitions (a transition that skips an input word) as well as self-loops (a transition that repeats the insertion of an input word).
Let WFSA-$\epsilon$ be defined by the tuple $F = \langle S,V,\pi, T, \eta \rangle$ where $S$ is the set of states of size $d$, $V$ is the vocabulary, $ \pi \in \mathbb{R}^d $ is an initial weight vector, $T: (V \cup \epsilon) \to \mathbb{R}^{d \times d}$

\subsection{SoPa as a WFSA}

Let the WSFA with $\epsilon$ transitions, i.e.\ a transition that does not consume a token, be defined by the tuple 

what sopa defines and does for 1 pattern


how patterns are aggregated and scoring a document


\subsection{Scoring a document}



\section{Domain Adaptation with SoPa}

explain training proc here


\section{Experimental Setup}

We build upon the implementation of SoPa introduced by \citet{schwartz2018sopa}.\footnote{\url{https://github.com/Noahs-ARK/soft_patterns}} All models are implemented in PyTorch\footnote{\url{https://pytorch.org/}}.

\subsection{Dataset}

We use the provided dataset, a balanced subset of the reviews data extracted by \citet{mcauley2015image}. The data consists of users reviews on two domains --movies and TV, and games--, extracted from Amazon.
We use Movies \& TV category as source domain and Games as target domain. We extract a development subset from the source domain and further divide the target domain's data into unlabeled, development, and test splits. Table~\ref{table:data-splits} presents the sizes of each split considered in the experiments.

\begin{table*}[]
\centering
\begin{tabular}{|l|c|r|r|c|}
\hline
Domain              & Train                       & \multicolumn{1}{c|}{Dev} & \multicolumn{1}{c|}{Test} & Unlabeled                  \\ \hline
Movies \& TV (src) & \multicolumn{1}{r|}{89,998} & 17,999                   & 10,000                    & -                          \\ \hline
Games (tgt)         & -                           & 5,000                    & 11,142                    & \multicolumn{1}{r|}{5,000} \\ \hline
\end{tabular}
\caption{Size of data splits in source (src) and target (tgt) domains.}
\label{table:data-splits}
\end{table*}

\subsection{Training of source domain}

We use pre-trained 300-dimensional GloVe 840B embeddings \citet{pennington2014glove} normalized to unit length. Training was performed using Adam \cite{kingma2014adam} as optimizer.

For hyper-parameter tunning, we resort to a subset of the training and development source data, consisting of 10,000 and 5,000 instances, respectively. These subsets were sampled following a uniform distribution without replacement. We use a Tree-structured Parzen Estimator (TPE) optimization model over 30 iterations\footnote{We use HyperOpt library (\url{http://hyperopt.github.io/hyperopt/})}. Table~\ref{table:param-tuning} shows the range of hyper-paramter values explored and their optimal values.

\begin{table*}[]
\centering
\begin{tabular}{|l|r|r|}
\hline
\multicolumn{1}{|c|}{Hyper-parameter} & \multicolumn{1}{c|}{Range}                                                                       & \multicolumn{1}{c|}{Optimal} \\ \hline
Patterns                              & \begin{tabular}[c]{@{}r@{}}\{6:10, 5:10, 4:10, 3:10, 2:10\},\\ \{6:10, 5:10, 4:10\}\end{tabular} & \{6:10, 5:10, 4:10\}         \\ \hline
Learning rate                         & $10^{-9}$--$10^{-2}$                                         & 0.00015                      \\ \hline
Dropout                               & 0--0.2                                                                                           & 0.0017                       \\ \hline
MLP hid. dim.                         & 100--300                                                                                         & 100                          \\ \hline
Batch size                            & 10--64                                                                                           & 20                           \\ \hline
\end{tabular}
\caption{Range and optimal values of hyper-parameters tuned.}
\label{table:param-tuning}
\end{table*}


\subsection{Self-training of target domain}




\section{Results and Discussion}




\bibliographystyle{acl_natbib}
\bibliography{naaclhlt2019}


\end{document}
